{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A notebook to run the entire pipeline using the ground-truth noise classifier during the graph-contruction phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "\n",
    "from gnn_tracking.training.tc import TCModule\n",
    "from gnn_tracking.models.graph_construction import MLGraphConstructionFromChkpt\n",
    "from gnn_tracking.models.track_condensation_networks import GraphTCNForMLGCPipeline\n",
    "from gnn_tracking.metrics.losses.metric_learning import GraphConstructionHingeEmbeddingLoss\n",
    "from gnn_tracking.postprocessing.dbscanscanner import DBSCANHyperParamScanner\n",
    "from pytorch_lightning import Trainer\n",
    "from gnn_tracking.utils.loading import TrackingDataModule\n",
    "from gnn_tracking.training.callbacks import PrintValidationMetrics\n",
    "from gnn_tracking.utils.versioning import assert_version_geq\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch import nn\n",
    "\n",
    "assert_version_geq(\"23.12.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = Path.cwd().resolve().parent.parent / \"test-data\" / \"data\" / \"point_clouds\" / \"v8\"\n",
    "data_dir = Path(\"/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v8/part_1\")\n",
    "assert data_dir.is_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = TrackingDataModule(\n",
    "    train=dict(\n",
    "        dirs=[data_dir],\n",
    "        stop=1,\n",
    "    ),\n",
    "    val=dict(\n",
    "        dirs=[data_dir],\n",
    "        start=1,\n",
    "        stop=2,\n",
    "    ),\n",
    "    identifier=\"point_clouds_v8\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:198: Attribute 'hc_in' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['hc_in'])`.\n"
     ]
    }
   ],
   "source": [
    "model = GraphTCNForMLGCPipeline(\n",
    "    node_indim=22,\n",
    "    edge_indim=44,\n",
    "    h_dim=192,\n",
    "    e_dim=192,\n",
    "    hidden_dim=192,\n",
    "    h_outdim=24,\n",
    "    L_hc=5,\n",
    "    alpha_latent=0.5,\n",
    "    n_embedding_coords=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[04:24:26] DEBUG: Getting class MLModule from module gnn_tracking.training.ml\u001b[0m\n",
      "\u001b[36m[04:24:26] DEBUG: Loading checkpoint ~/gnn_tracking/tutorials/notebooks/lightning_logs/version_53977655/checkpoints/epoch=999-step=1000.ckpt\u001b[0m\n",
      "\u001b[36m[04:24:26] DEBUG: Getting class GraphConstructionFCNN from module gnn_tracking.models.graph_construction\u001b[0m\n",
      "\u001b[36m[04:24:26] DEBUG: Getting class NoiseClassifierModel from module gnn_tracking.models.graph_construction\u001b[0m\n",
      "\u001b[36m[04:24:26] DEBUG: Getting class GraphConstructionHingeEmbeddingLoss from module gnn_tracking.metrics.losses.metric_learning\u001b[0m\n",
      "\u001b[36m[04:24:27] DEBUG: Checkpoint loaded. Model ready to go.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "preproc = MLGraphConstructionFromChkpt(\n",
    "    ml_chkpt_path=\"~/gnn_tracking/tutorials/notebooks/lightning_logs/version_53977655/checkpoints/epoch=999-step=1000.ckpt\",\n",
    "    max_num_neighbors=10,\n",
    "    max_radius=1,\n",
    "    use_embedding_features=True,\n",
    "    build_edge_features=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fct = GraphConstructionHingeEmbeddingLoss(\n",
    "    lw_repulsive=0.05,\n",
    "    pt_thld=0.9,\n",
    "    max_num_neighbors=256,\n",
    "    p_attr=2,\n",
    "    p_rep=2,\n",
    "    r_emb=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_scanner = DBSCANHyperParamScanner(\n",
    "    n_trials=60,\n",
    "    n_jobs=6,\n",
    "    keep_best=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmodel = TCModule(\n",
    "    model=model,\n",
    "    preproc=preproc,\n",
    "    loss_fct=loss_fct,\n",
    "    cluster_scanner=cluster_scanner,\n",
    "    optimizer=partial(torch.optim.Adam, lr=8*1e-4),\n",
    "    scheduler=partial(torch.optim.lr_scheduler.LinearLR,\n",
    "                                            start_factor=1,\n",
    "                                            end_factor=0.1,\n",
    "                                            total_iters=50)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A100 80GB PCIe MIG 1g.10gb') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[32m[04:24:36] INFO: DataLoader will load 1 graphs (out of 900 available).\u001b[0m\n",
      "\u001b[36m[04:24:36] DEBUG: First graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v8/part_1/data21000_s0.pt, last graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v8/part_1/data21000_s0.pt\u001b[0m\n",
      "\u001b[32m[04:24:36] INFO: DataLoader will load 1 graphs (out of 900 available).\u001b[0m\n",
      "\u001b[36m[04:24:36] DEBUG: First graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v8/part_1/data21001_s0.pt, last graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v8/part_1/data21001_s0.pt\u001b[0m\n",
      "/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:639: Checkpoint directory /home/aj2239/gnn_tracking/tutorials/notebooks/lightning_logs/version_53977655/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [MIG-74d68ce8-f74a-5408-a325-06b493f31c14]\n",
      "\n",
      "  | Name     | Type                                | Params\n",
      "-----------------------------------------------------------------\n",
      "0 | model    | GraphTCNForMLGCPipeline             | 1.9 M \n",
      "1 | preproc  | MLGraphConstruction                 | 17.8 K\n",
      "2 | loss_fct | GraphConstructionHingeEmbeddingLoss | 0     \n",
      "-----------------------------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "17.8 K    Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.688     Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=1` in the `DataLoader` to improve performance.\n",
      "/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=1` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c09bdda6b04e0d814d3b8a78497567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[04:26:31] WARNING: WARNING: ran out of memory (OOM), skipping batch. If this happens frequently, decrease the batch size. Will abort if we get 10 consecutive OOM errors.\u001b[0m\n",
      "/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:129: `training_step` returned `None`. If this was on purpose, ignore this warning...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                    Validation epoch=0                    \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mMetric                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Value\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mError\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━┩\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mattractive                    \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      4.04002\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ attractive_weighted            │       4.04002 │   nan │\n",
      "│ best_dbscan_eps                │       0.03504 │   nan │\n",
      "│ best_dbscan_min_samples        │       3.00000 │   nan │\n",
      "│ n_edges_att                    │   37293.00000 │   nan │\n",
      "│ n_edges_rep                    │ 2588201.00000 │   nan │\n",
      "│ n_hits_oi                      │   10284.00000 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mrepulsive                     \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m    106.52499\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ repulsive_weighted             │       5.32625 │   nan │\n",
      "│ total                          │       9.36627 │   nan │\n",
      "│ trk.double_majority            │       0.00071 │   nan │\n",
      "│ trk.double_majority_pt0.5      │       0.00079 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.double_majority_pt0.9     \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.00132\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.double_majority_pt1.5      │       0.00000 │   nan │\n",
      "│ trk.fake_double_majority       │       0.99741 │   nan │\n",
      "│ trk.fake_double_majority_pt0.5 │       0.99697 │   nan │\n",
      "│ trk.fake_double_majority_pt0.9 │       0.99468 │   nan │\n",
      "│ trk.fake_double_majority_pt1.5 │       1.00000 │   nan │\n",
      "│ trk.fake_lhc                   │       0.98963 │   nan │\n",
      "│ trk.fake_lhc_pt0.5             │       0.99395 │   nan │\n",
      "│ trk.fake_lhc_pt0.9             │       0.99468 │   nan │\n",
      "│ trk.fake_lhc_pt1.5             │       1.00000 │   nan │\n",
      "│ trk.fake_perfect               │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt0.5         │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt0.9         │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt1.5         │       1.00000 │   nan │\n",
      "│ trk.i_batch                    │       0.00000 │   nan │\n",
      "│ trk.lhc                        │       0.01037 │   nan │\n",
      "│ trk.lhc_pt0.5                  │       0.00605 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.lhc_pt0.9                 \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.00532\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.lhc_pt1.5                  │       0.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters         │    2314.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt0.5   │     991.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt0.9   │     376.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt1.5   │     126.00000 │   nan │\n",
      "│ trk.n_particles                │    8410.00000 │   nan │\n",
      "│ trk.n_particles_pt0.5          │    3820.00000 │   nan │\n",
      "│ trk.n_particles_pt0.9          │    1512.00000 │   nan │\n",
      "│ trk.n_particles_pt1.5          │     505.00000 │   nan │\n",
      "│ trk.perfect                    │       0.00000 │   nan │\n",
      "│ trk.perfect_pt0.5              │       0.00000 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.perfect_pt0.9             \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.00000\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.perfect_pt1.5              │       0.00000 │   nan │\n",
      "└────────────────────────────────┴───────────────┴───────┘\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[04:27:44] WARNING: WARNING: ran out of memory (OOM), skipping batch. If this happens frequently, decrease the batch size. Will abort if we get 10 consecutive OOM errors.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                    Validation epoch=1                    \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mMetric                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Value\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mError\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━┩\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mattractive                    \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      4.04002\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ attractive_weighted            │       4.04002 │   nan │\n",
      "│ best_dbscan_eps                │       0.06255 │   nan │\n",
      "│ best_dbscan_min_samples        │       1.00000 │   nan │\n",
      "│ n_edges_att                    │   37293.00000 │   nan │\n",
      "│ n_edges_rep                    │ 2588202.00000 │   nan │\n",
      "│ n_hits_oi                      │   10284.00000 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mrepulsive                     \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m    106.52500\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ repulsive_weighted             │       5.32625 │   nan │\n",
      "│ total                          │       9.36627 │   nan │\n",
      "│ trk.double_majority            │       0.00012 │   nan │\n",
      "│ trk.double_majority_pt0.5      │       0.00026 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.double_majority_pt0.9     \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.00066\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.double_majority_pt1.5      │       0.00000 │   nan │\n",
      "│ trk.fake_double_majority       │       0.99938 │   nan │\n",
      "│ trk.fake_double_majority_pt0.5 │       0.99862 │   nan │\n",
      "│ trk.fake_double_majority_pt0.9 │       0.99654 │   nan │\n",
      "│ trk.fake_double_majority_pt1.5 │       1.00000 │   nan │\n",
      "│ trk.fake_lhc                   │       0.99815 │   nan │\n",
      "│ trk.fake_lhc_pt0.5             │       0.99587 │   nan │\n",
      "│ trk.fake_lhc_pt0.9             │       0.99654 │   nan │\n",
      "│ trk.fake_lhc_pt1.5             │       1.00000 │   nan │\n",
      "│ trk.fake_perfect               │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt0.5         │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt0.9         │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt1.5         │       1.00000 │   nan │\n",
      "│ trk.i_batch                    │       0.00000 │   nan │\n",
      "│ trk.lhc                        │       0.00185 │   nan │\n",
      "│ trk.lhc_pt0.5                  │       0.00413 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.lhc_pt0.9                 \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.00346\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.lhc_pt1.5                  │       0.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters         │    1622.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt0.5   │     727.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt0.9   │     289.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt1.5   │     102.00000 │   nan │\n",
      "│ trk.n_particles                │    8410.00000 │   nan │\n",
      "│ trk.n_particles_pt0.5          │    3820.00000 │   nan │\n",
      "│ trk.n_particles_pt0.9          │    1512.00000 │   nan │\n",
      "│ trk.n_particles_pt1.5          │     505.00000 │   nan │\n",
      "│ trk.perfect                    │       0.00000 │   nan │\n",
      "│ trk.perfect_pt0.5              │       0.00000 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.perfect_pt0.9             \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.00000\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.perfect_pt1.5              │       0.00000 │   nan │\n",
      "└────────────────────────────────┴───────────────┴───────┘\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[04:28:53] WARNING: WARNING: ran out of memory (OOM), skipping batch. If this happens frequently, decrease the batch size. Will abort if we get 10 consecutive OOM errors.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                    Validation epoch=2                    \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mMetric                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Value\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mError\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━┩\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mattractive                    \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      4.04002\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ attractive_weighted            │       4.04002 │   nan │\n",
      "│ best_dbscan_eps                │       0.05740 │   nan │\n",
      "│ best_dbscan_min_samples        │       4.00000 │   nan │\n",
      "│ n_edges_att                    │   37293.00000 │   nan │\n",
      "│ n_edges_rep                    │ 2588202.00000 │   nan │\n",
      "│ n_hits_oi                      │   10284.00000 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mrepulsive                     \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m    106.52499\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ repulsive_weighted             │       5.32625 │   nan │\n",
      "│ total                          │       9.36627 │   nan │\n",
      "│ trk.double_majority            │       0.00012 │   nan │\n",
      "│ trk.double_majority_pt0.5      │       0.00026 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.double_majority_pt0.9     \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.00066\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.double_majority_pt1.5      │       0.00000 │   nan │\n",
      "│ trk.fake_double_majority       │       0.99907 │   nan │\n",
      "│ trk.fake_double_majority_pt0.5 │       0.99794 │   nan │\n",
      "│ trk.fake_double_majority_pt0.9 │       0.99492 │   nan │\n",
      "│ trk.fake_double_majority_pt1.5 │       1.00000 │   nan │\n",
      "│ trk.fake_lhc                   │       0.99907 │   nan │\n",
      "│ trk.fake_lhc_pt0.5             │       0.99794 │   nan │\n",
      "│ trk.fake_lhc_pt0.9             │       0.99492 │   nan │\n",
      "│ trk.fake_lhc_pt1.5             │       1.00000 │   nan │\n",
      "│ trk.fake_perfect               │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt0.5         │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt0.9         │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt1.5         │       1.00000 │   nan │\n",
      "│ trk.i_batch                    │       0.00000 │   nan │\n",
      "│ trk.lhc                        │       0.00093 │   nan │\n",
      "│ trk.lhc_pt0.5                  │       0.00206 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.lhc_pt0.9                 \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.00508\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.lhc_pt1.5                  │       0.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters         │    1076.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt0.5   │     486.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt0.9   │     197.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt1.5   │      65.00000 │   nan │\n",
      "│ trk.n_particles                │    8410.00000 │   nan │\n",
      "│ trk.n_particles_pt0.5          │    3820.00000 │   nan │\n",
      "│ trk.n_particles_pt0.9          │    1512.00000 │   nan │\n",
      "│ trk.n_particles_pt1.5          │     505.00000 │   nan │\n",
      "│ trk.perfect                    │       0.00000 │   nan │\n",
      "│ trk.perfect_pt0.5              │       0.00000 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.perfect_pt0.9             \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.00000\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.perfect_pt1.5              │       0.00000 │   nan │\n",
      "└────────────────────────────────┴───────────────┴───────┘\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[04:30:10] WARNING: WARNING: ran out of memory (OOM), skipping batch. If this happens frequently, decrease the batch size. Will abort if we get 10 consecutive OOM errors.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                    Validation epoch=3                    \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mMetric                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Value\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mError\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━┩\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mattractive                    \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      4.04002\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ attractive_weighted            │       4.04002 │   nan │\n",
      "│ best_dbscan_eps                │       0.02001 │   nan │\n",
      "│ best_dbscan_min_samples        │       2.00000 │   nan │\n",
      "│ n_edges_att                    │   37293.00000 │   nan │\n",
      "│ n_edges_rep                    │ 2588202.00000 │   nan │\n",
      "│ n_hits_oi                      │   10284.00000 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mrepulsive                     \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m    106.52499\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ repulsive_weighted             │       5.32625 │   nan │\n",
      "│ total                          │       9.36627 │   nan │\n",
      "│ trk.double_majority            │       0.00036 │   nan │\n",
      "│ trk.double_majority_pt0.5      │       0.00052 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.double_majority_pt0.9     \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.00132\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.double_majority_pt1.5      │       0.00000 │   nan │\n",
      "│ trk.fake_double_majority       │       0.99903 │   nan │\n",
      "│ trk.fake_double_majority_pt0.5 │       0.99858 │   nan │\n",
      "│ trk.fake_double_majority_pt0.9 │       0.99623 │   nan │\n",
      "│ trk.fake_double_majority_pt1.5 │       1.00000 │   nan │\n",
      "│ trk.fake_lhc                   │       0.98478 │   nan │\n",
      "│ trk.fake_lhc_pt0.5             │       0.98579 │   nan │\n",
      "│ trk.fake_lhc_pt0.9             │       0.98302 │   nan │\n",
      "│ trk.fake_lhc_pt1.5             │       0.98396 │   nan │\n",
      "│ trk.fake_perfect               │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt0.5         │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt0.9         │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt1.5         │       1.00000 │   nan │\n",
      "│ trk.i_batch                    │       0.00000 │   nan │\n",
      "│ trk.lhc                        │       0.01522 │   nan │\n",
      "│ trk.lhc_pt0.5                  │       0.01421 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.lhc_pt0.9                 \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.01698\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.lhc_pt1.5                  │       0.01604 │   nan │\n",
      "│ trk.n_cleaned_clusters         │    3089.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt0.5   │    1407.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt0.9   │     530.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt1.5   │     187.00000 │   nan │\n",
      "│ trk.n_particles                │    8410.00000 │   nan │\n",
      "│ trk.n_particles_pt0.5          │    3820.00000 │   nan │\n",
      "│ trk.n_particles_pt0.9          │    1512.00000 │   nan │\n",
      "│ trk.n_particles_pt1.5          │     505.00000 │   nan │\n",
      "│ trk.perfect                    │       0.00000 │   nan │\n",
      "│ trk.perfect_pt0.5              │       0.00000 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.perfect_pt0.9             \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.00000\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.perfect_pt1.5              │       0.00000 │   nan │\n",
      "└────────────────────────────────┴───────────────┴───────┘\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[04:31:13] WARNING: WARNING: ran out of memory (OOM), skipping batch. If this happens frequently, decrease the batch size. Will abort if we get 10 consecutive OOM errors.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                    Validation epoch=4                    \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mMetric                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Value\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mError\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━┩\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mattractive                    \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      4.04002\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ attractive_weighted            │       4.04002 │   nan │\n",
      "│ best_dbscan_eps                │       0.07509 │   nan │\n",
      "│ best_dbscan_min_samples        │       3.00000 │   nan │\n",
      "│ n_edges_att                    │   37293.00000 │   nan │\n",
      "│ n_edges_rep                    │ 2588201.00000 │   nan │\n",
      "│ n_hits_oi                      │   10284.00000 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mrepulsive                     \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m    106.52499\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ repulsive_weighted             │       5.32625 │   nan │\n",
      "│ total                          │       9.36627 │   nan │\n",
      "│ trk.double_majority            │       0.00012 │   nan │\n",
      "│ trk.double_majority_pt0.5      │       0.00026 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.double_majority_pt0.9     \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.00066\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.double_majority_pt1.5      │       0.00000 │   nan │\n",
      "│ trk.fake_double_majority       │       0.99919 │   nan │\n",
      "│ trk.fake_double_majority_pt0.5 │       0.99822 │   nan │\n",
      "│ trk.fake_double_majority_pt0.9 │       0.99548 │   nan │\n",
      "│ trk.fake_double_majority_pt1.5 │       1.00000 │   nan │\n",
      "│ trk.fake_lhc                   │       0.99919 │   nan │\n",
      "│ trk.fake_lhc_pt0.5             │       0.99822 │   nan │\n",
      "│ trk.fake_lhc_pt0.9             │       0.99548 │   nan │\n",
      "│ trk.fake_lhc_pt1.5             │       1.00000 │   nan │\n",
      "│ trk.fake_perfect               │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt0.5         │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt0.9         │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt1.5         │       1.00000 │   nan │\n",
      "│ trk.i_batch                    │       0.00000 │   nan │\n",
      "│ trk.lhc                        │       0.00081 │   nan │\n",
      "│ trk.lhc_pt0.5                  │       0.00178 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.lhc_pt0.9                 \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.00452\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.lhc_pt1.5                  │       0.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters         │    1229.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt0.5   │     562.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt0.9   │     221.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt1.5   │      72.00000 │   nan │\n",
      "│ trk.n_particles                │    8410.00000 │   nan │\n",
      "│ trk.n_particles_pt0.5          │    3820.00000 │   nan │\n",
      "│ trk.n_particles_pt0.9          │    1512.00000 │   nan │\n",
      "│ trk.n_particles_pt1.5          │     505.00000 │   nan │\n",
      "│ trk.perfect                    │       0.00000 │   nan │\n",
      "│ trk.perfect_pt0.5              │       0.00000 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.perfect_pt0.9             \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.00000\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.perfect_pt1.5              │       0.00000 │   nan │\n",
      "└────────────────────────────────┴───────────────┴───────┘\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[04:32:17] WARNING: WARNING: ran out of memory (OOM), skipping batch. If this happens frequently, decrease the batch size. Will abort if we get 10 consecutive OOM errors.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                    Validation epoch=5                    \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mMetric                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Value\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mError\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━┩\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mattractive                    \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      4.04002\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ attractive_weighted            │       4.04002 │   nan │\n",
      "│ best_dbscan_eps                │       0.06471 │   nan │\n",
      "│ best_dbscan_min_samples        │       1.00000 │   nan │\n",
      "│ n_edges_att                    │   37293.00000 │   nan │\n",
      "│ n_edges_rep                    │ 2588202.00000 │   nan │\n",
      "│ n_hits_oi                      │   10284.00000 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mrepulsive                     \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m    106.52499\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ repulsive_weighted             │       5.32625 │   nan │\n",
      "│ total                          │       9.36627 │   nan │\n",
      "│ trk.double_majority            │       0.00012 │   nan │\n",
      "│ trk.double_majority_pt0.5      │       0.00026 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.double_majority_pt0.9     \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.00066\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.double_majority_pt1.5      │       0.00000 │   nan │\n",
      "│ trk.fake_double_majority       │       0.99935 │   nan │\n",
      "│ trk.fake_double_majority_pt0.5 │       0.99857 │   nan │\n",
      "│ trk.fake_double_majority_pt0.9 │       0.99645 │   nan │\n",
      "│ trk.fake_double_majority_pt1.5 │       1.00000 │   nan │\n",
      "│ trk.fake_lhc                   │       0.99871 │   nan │\n",
      "│ trk.fake_lhc_pt0.5             │       0.99714 │   nan │\n",
      "│ trk.fake_lhc_pt0.9             │       0.99645 │   nan │\n",
      "│ trk.fake_lhc_pt1.5             │       1.00000 │   nan │\n",
      "│ trk.fake_perfect               │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt0.5         │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt0.9         │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt1.5         │       1.00000 │   nan │\n",
      "│ trk.i_batch                    │       0.00000 │   nan │\n",
      "│ trk.lhc                        │       0.00129 │   nan │\n",
      "│ trk.lhc_pt0.5                  │       0.00286 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.lhc_pt0.9                 \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.00355\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.lhc_pt1.5                  │       0.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters         │    1546.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt0.5   │     700.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt0.9   │     282.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt1.5   │     109.00000 │   nan │\n",
      "│ trk.n_particles                │    8410.00000 │   nan │\n",
      "│ trk.n_particles_pt0.5          │    3820.00000 │   nan │\n",
      "│ trk.n_particles_pt0.9          │    1512.00000 │   nan │\n",
      "│ trk.n_particles_pt1.5          │     505.00000 │   nan │\n",
      "│ trk.perfect                    │       0.00000 │   nan │\n",
      "│ trk.perfect_pt0.5              │       0.00000 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.perfect_pt0.9             \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.00000\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.perfect_pt1.5              │       0.00000 │   nan │\n",
      "└────────────────────────────────┴───────────────┴───────┘\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[04:33:26] WARNING: WARNING: ran out of memory (OOM), skipping batch. If this happens frequently, decrease the batch size. Will abort if we get 10 consecutive OOM errors.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                    Validation epoch=6                    \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mMetric                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Value\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mError\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━┩\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mattractive                    \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      4.04002\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ attractive_weighted            │       4.04002 │   nan │\n",
      "│ best_dbscan_eps                │       0.00158 │   nan │\n",
      "│ best_dbscan_min_samples        │       2.00000 │   nan │\n",
      "│ n_edges_att                    │   37293.00000 │   nan │\n",
      "│ n_edges_rep                    │ 2588202.00000 │   nan │\n",
      "│ n_hits_oi                      │   10284.00000 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mrepulsive                     \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m    106.52499\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ repulsive_weighted             │       5.32625 │   nan │\n",
      "│ total                          │       9.36627 │   nan │\n",
      "│ trk.double_majority            │       0.00000 │   nan │\n",
      "│ trk.double_majority_pt0.5      │       0.00000 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.double_majority_pt0.9     \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.00000\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.double_majority_pt1.5      │       0.00000 │   nan │\n",
      "│ trk.fake_double_majority       │       1.00000 │   nan │\n",
      "│ trk.fake_double_majority_pt0.5 │       1.00000 │   nan │\n",
      "│ trk.fake_double_majority_pt0.9 │       1.00000 │   nan │\n",
      "│ trk.fake_double_majority_pt1.5 │           nan │   nan │\n",
      "│ trk.fake_lhc                   │       1.00000 │   nan │\n",
      "│ trk.fake_lhc_pt0.5             │       1.00000 │   nan │\n",
      "│ trk.fake_lhc_pt0.9             │       1.00000 │   nan │\n",
      "│ trk.fake_lhc_pt1.5             │           nan │   nan │\n",
      "│ trk.fake_perfect               │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt0.5         │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt0.9         │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt1.5         │           nan │   nan │\n",
      "│ trk.i_batch                    │       0.00000 │   nan │\n",
      "│ trk.lhc                        │       0.00000 │   nan │\n",
      "│ trk.lhc_pt0.5                  │       0.00000 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.lhc_pt0.9                 \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.00000\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.lhc_pt1.5                  │           nan │   nan │\n",
      "│ trk.n_cleaned_clusters         │       3.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt0.5   │       1.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt0.9   │       1.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt1.5   │       0.00000 │   nan │\n",
      "│ trk.n_particles                │    8410.00000 │   nan │\n",
      "│ trk.n_particles_pt0.5          │    3820.00000 │   nan │\n",
      "│ trk.n_particles_pt0.9          │    1512.00000 │   nan │\n",
      "│ trk.n_particles_pt1.5          │     505.00000 │   nan │\n",
      "│ trk.perfect                    │       0.00000 │   nan │\n",
      "│ trk.perfect_pt0.5              │       0.00000 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.perfect_pt0.9             \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.00000\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.perfect_pt1.5              │       0.00000 │   nan │\n",
      "└────────────────────────────────┴───────────────┴───────┘\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[04:34:31] WARNING: WARNING: ran out of memory (OOM), skipping batch. If this happens frequently, decrease the batch size. Will abort if we get 10 consecutive OOM errors.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                    Validation epoch=7                    \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mMetric                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Value\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mError\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━┩\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mattractive                    \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      4.04002\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ attractive_weighted            │       4.04002 │   nan │\n",
      "│ best_dbscan_eps                │       0.05500 │   nan │\n",
      "│ best_dbscan_min_samples        │       3.00000 │   nan │\n",
      "│ n_edges_att                    │   37293.00000 │   nan │\n",
      "│ n_edges_rep                    │ 2588202.00000 │   nan │\n",
      "│ n_hits_oi                      │   10284.00000 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mrepulsive                     \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m    106.52499\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ repulsive_weighted             │       5.32625 │   nan │\n",
      "│ total                          │       9.36627 │   nan │\n",
      "│ trk.double_majority            │       0.00012 │   nan │\n",
      "│ trk.double_majority_pt0.5      │       0.00026 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.double_majority_pt0.9     \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.00066\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.double_majority_pt1.5      │       0.00000 │   nan │\n",
      "│ trk.fake_double_majority       │       0.99944 │   nan │\n",
      "│ trk.fake_double_majority_pt0.5 │       0.99873 │   nan │\n",
      "│ trk.fake_double_majority_pt0.9 │       0.99693 │   nan │\n",
      "│ trk.fake_double_majority_pt1.5 │       1.00000 │   nan │\n",
      "│ trk.fake_lhc                   │       0.99888 │   nan │\n",
      "│ trk.fake_lhc_pt0.5             │       0.99873 │   nan │\n",
      "│ trk.fake_lhc_pt0.9             │       0.99693 │   nan │\n",
      "│ trk.fake_lhc_pt1.5             │       1.00000 │   nan │\n",
      "│ trk.fake_perfect               │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt0.5         │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt0.9         │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt1.5         │       1.00000 │   nan │\n",
      "│ trk.i_batch                    │       0.00000 │   nan │\n",
      "│ trk.lhc                        │       0.00112 │   nan │\n",
      "│ trk.lhc_pt0.5                  │       0.00127 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.lhc_pt0.9                 \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.00307\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.lhc_pt1.5                  │       0.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters         │    1783.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt0.5   │     790.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt0.9   │     326.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt1.5   │     124.00000 │   nan │\n",
      "│ trk.n_particles                │    8410.00000 │   nan │\n",
      "│ trk.n_particles_pt0.5          │    3820.00000 │   nan │\n",
      "│ trk.n_particles_pt0.9          │    1512.00000 │   nan │\n",
      "│ trk.n_particles_pt1.5          │     505.00000 │   nan │\n",
      "│ trk.perfect                    │       0.00000 │   nan │\n",
      "│ trk.perfect_pt0.5              │       0.00000 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.perfect_pt0.9             \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.00000\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.perfect_pt1.5              │       0.00000 │   nan │\n",
      "└────────────────────────────────┴───────────────┴───────┘\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[04:35:25] WARNING: WARNING: ran out of memory (OOM), skipping batch. If this happens frequently, decrease the batch size. Will abort if we get 10 consecutive OOM errors.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                    Validation epoch=8                    \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mMetric                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Value\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mError\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━┩\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mattractive                    \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      4.04002\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ attractive_weighted            │       4.04002 │   nan │\n",
      "│ best_dbscan_eps                │       0.06704 │   nan │\n",
      "│ best_dbscan_min_samples        │       1.00000 │   nan │\n",
      "│ n_edges_att                    │   37293.00000 │   nan │\n",
      "│ n_edges_rep                    │ 2588201.00000 │   nan │\n",
      "│ n_hits_oi                      │   10284.00000 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mrepulsive                     \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m    106.52499\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ repulsive_weighted             │       5.32625 │   nan │\n",
      "│ total                          │       9.36627 │   nan │\n",
      "│ trk.double_majority            │       0.00012 │   nan │\n",
      "│ trk.double_majority_pt0.5      │       0.00026 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.double_majority_pt0.9     \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.00066\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.double_majority_pt1.5      │       0.00000 │   nan │\n",
      "│ trk.fake_double_majority       │       0.99930 │   nan │\n",
      "│ trk.fake_double_majority_pt0.5 │       0.99844 │   nan │\n",
      "│ trk.fake_double_majority_pt0.9 │       0.99602 │   nan │\n",
      "│ trk.fake_double_majority_pt1.5 │       1.00000 │   nan │\n",
      "│ trk.fake_lhc                   │       0.99859 │   nan │\n",
      "│ trk.fake_lhc_pt0.5             │       0.99687 │   nan │\n",
      "│ trk.fake_lhc_pt0.9             │       0.99602 │   nan │\n",
      "│ trk.fake_lhc_pt1.5             │       1.00000 │   nan │\n",
      "│ trk.fake_perfect               │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt0.5         │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt0.9         │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt1.5         │       1.00000 │   nan │\n",
      "│ trk.i_batch                    │       0.00000 │   nan │\n",
      "│ trk.lhc                        │       0.00141 │   nan │\n",
      "│ trk.lhc_pt0.5                  │       0.00313 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.lhc_pt0.9                 \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.00398\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.lhc_pt1.5                  │       0.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters         │    1420.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt0.5   │     640.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt0.9   │     251.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt1.5   │      87.00000 │   nan │\n",
      "│ trk.n_particles                │    8410.00000 │   nan │\n",
      "│ trk.n_particles_pt0.5          │    3820.00000 │   nan │\n",
      "│ trk.n_particles_pt0.9          │    1512.00000 │   nan │\n",
      "│ trk.n_particles_pt1.5          │     505.00000 │   nan │\n",
      "│ trk.perfect                    │       0.00000 │   nan │\n",
      "│ trk.perfect_pt0.5              │       0.00000 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.perfect_pt0.9             \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.00000\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.perfect_pt1.5              │       0.00000 │   nan │\n",
      "└────────────────────────────────┴───────────────┴───────┘\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[04:36:38] WARNING: WARNING: ran out of memory (OOM), skipping batch. If this happens frequently, decrease the batch size. Will abort if we get 10 consecutive OOM errors.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "219984a70ff04b8f85feb70fdc9de50d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n",
      "NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                    Validation epoch=9                    \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mMetric                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Value\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mError\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━┩\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mattractive                    \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      4.04002\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ attractive_weighted            │       4.04002 │   nan │\n",
      "│ best_dbscan_eps                │       0.02085 │   nan │\n",
      "│ best_dbscan_min_samples        │       1.00000 │   nan │\n",
      "│ n_edges_att                    │   37293.00000 │   nan │\n",
      "│ n_edges_rep                    │ 2588199.00000 │   nan │\n",
      "│ n_hits_oi                      │   10284.00000 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mrepulsive                     \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m    106.52496\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ repulsive_weighted             │       5.32625 │   nan │\n",
      "│ total                          │       9.36627 │   nan │\n",
      "│ trk.double_majority            │       0.00036 │   nan │\n",
      "│ trk.double_majority_pt0.5      │       0.00052 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.double_majority_pt0.9     \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.00132\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.double_majority_pt1.5      │       0.00000 │   nan │\n",
      "│ trk.fake_double_majority       │       0.99903 │   nan │\n",
      "│ trk.fake_double_majority_pt0.5 │       0.99857 │   nan │\n",
      "│ trk.fake_double_majority_pt0.9 │       0.99626 │   nan │\n",
      "│ trk.fake_double_majority_pt1.5 │       1.00000 │   nan │\n",
      "│ trk.fake_lhc                   │       0.98647 │   nan │\n",
      "│ trk.fake_lhc_pt0.5             │       0.98640 │   nan │\n",
      "│ trk.fake_lhc_pt0.9             │       0.98505 │   nan │\n",
      "│ trk.fake_lhc_pt1.5             │       0.98462 │   nan │\n",
      "│ trk.fake_perfect               │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt0.5         │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt0.9         │       1.00000 │   nan │\n",
      "│ trk.fake_perfect_pt1.5         │       1.00000 │   nan │\n",
      "│ trk.i_batch                    │       0.00000 │   nan │\n",
      "│ trk.lhc                        │       0.01353 │   nan │\n",
      "│ trk.lhc_pt0.5                  │       0.01360 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.lhc_pt0.9                 \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.01495\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.lhc_pt1.5                  │       0.01538 │   nan │\n",
      "│ trk.n_cleaned_clusters         │    3105.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt0.5   │    1397.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt0.9   │     535.00000 │   nan │\n",
      "│ trk.n_cleaned_clusters_pt1.5   │     195.00000 │   nan │\n",
      "│ trk.n_particles                │    8410.00000 │   nan │\n",
      "│ trk.n_particles_pt0.5          │    3820.00000 │   nan │\n",
      "│ trk.n_particles_pt0.9          │    1512.00000 │   nan │\n",
      "│ trk.n_particles_pt1.5          │     505.00000 │   nan │\n",
      "│ trk.perfect                    │       0.00000 │   nan │\n",
      "│ trk.perfect_pt0.5              │       0.00000 │   nan │\n",
      "│\u001b[1;95m \u001b[0m\u001b[1;95mtrk.perfect_pt0.9             \u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m      0.00000\u001b[0m\u001b[1;95m \u001b[0m│\u001b[1;95m \u001b[0m\u001b[1;95m  nan\u001b[0m\u001b[1;95m \u001b[0m│\n",
      "│ trk.perfect_pt1.5              │       0.00000 │   nan │\n",
      "└────────────────────────────────┴───────────────┴───────┘\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[04:37:44] WARNING: WARNING: ran out of memory (OOM), skipping batch. If this happens frequently, decrease the batch size. Will abort if we get 10 consecutive OOM errors.\u001b[0m\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"/home/aj2239/gnn_tracking/src/gnn_tracking/models/mlp.py\", line 49, in forward\n    def forward(self, x):\n        for layer in self.layers:\n            x = layer(x)\n                ~~~~~ <--- HERE\n        return x\n  File \"/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 101, in forward\n    def forward(self, input: Tensor) -> Tensor:\n        return F.relu(input, inplace=self.inplace)\n               ~~~~~~ <--- HERE\n  File \"/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/torch/nn/functional.py\", line 1471, in relu\n        result = torch.relu_(input)\n    else:\n        result = torch.relu(input)\n                 ~~~~~~~~~~ <--- HERE\n    return result\nRuntimeError: CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacty of 9.50 GiB of which 484.94 MiB is free. Process 3006315 has 106.00 MiB memory in use. Including non-PyTorch memory, this process has 8.91 GiB memory in use. Of the allocated memory 7.79 GiB is allocated by PyTorch, and 1.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      2\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m      3\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     log_every_n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      5\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[PrintValidationMetrics()],\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 7\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:989\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 989\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    994\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1035\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1035\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:202\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:359\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 359\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py:136\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py:240\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_optimization\u001b[38;5;241m.\u001b[39mrun(kwargs)\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:187\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m         closure()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:265\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_ready()\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_completed()\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:157\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 157\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    160\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/pytorch_lightning/core/module.py:1291\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimizer_step\u001b[39m(\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1254\u001b[0m     epoch: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1257\u001b[0m     optimizer_closure: Optional[Callable[[], Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1258\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1260\u001b[0m \u001b[38;5;124;03m    the optimizer.\u001b[39;00m\n\u001b[1;32m   1261\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1289\u001b[0m \n\u001b[1;32m   1290\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1291\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py:151\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py:230\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[0;32m--> 230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py:117\u001b[0m, in \u001b[0;36mPrecision.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:68\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     67\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/torch/optim/adam.py:143\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 143\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    146\u001b[0m     params_with_grad \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py:104\u001b[0m, in \u001b[0;36mPrecision._wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_closure\u001b[39m(\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     93\u001b[0m     model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     94\u001b[0m     optimizer: Optimizer,\n\u001b[1;32m     95\u001b[0m     closure: Callable[[], Any],\n\u001b[1;32m     96\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    hook is called.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m \n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m closure_result\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:140\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:126\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39menable_grad()\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ClosureResult:\n\u001b[0;32m--> 126\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarning_cache\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:315\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# manually capture logged metrics\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_result_cls\u001b[38;5;241m.\u001b[39mfrom_training_step_output(training_step_output, trainer\u001b[38;5;241m.\u001b[39maccumulate_grad_batches)\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:309\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 309\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    312\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py:382\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gnn_tracking/src/gnn_tracking/utils/oom.py:28\u001b[0m, in \u001b[0;36mtolerate_some_oom_errors.<locals>.wrapped_fct\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fct)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fct\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 28\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfct\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_oom_error(e):\n",
      "File \u001b[0;32m~/gnn_tracking/src/gnn_tracking/training/tc.py:75\u001b[0m, in \u001b[0;36mTCModule.training_step\u001b[0;34m(self, data, batch_idx)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;129m@tolerate_some_oom_errors\u001b[39m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtraining_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: Data, batch_idx: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m     74\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_preproc(data)\n\u001b[0;32m---> 75\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_preprocessed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     loss, loss_dct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_losses(out, data)\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_dict(\n\u001b[1;32m     78\u001b[0m         add_key_suffix(loss_dct, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_train\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     79\u001b[0m         prog_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     80\u001b[0m         on_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     81\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtrain_dataloader\u001b[38;5;241m.\u001b[39mbatch_size,  \u001b[38;5;66;03m# pyright: ignore[reportOptionalMemberAccess]\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     )\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/gnn_tracking/src/gnn_tracking/training/base.py:99\u001b[0m, in \u001b[0;36mTrackingModule.forward\u001b[0;34m(self, data, _preprocessed)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _preprocessed:\n\u001b[1;32m     98\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_preproc(data)\n\u001b[0;32m---> 99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gnn_tracking/src/gnn_tracking/models/track_condensation_networks.py:563\u001b[0m, in \u001b[0;36mGraphTCNForMLGCPipeline.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    561\u001b[0m     data: Data,\n\u001b[1;32m    562\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Tensor \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gtcn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gnn_tracking/src/gnn_tracking/models/track_condensation_networks.py:266\u001b[0m, in \u001b[0;36mModularGraphTCN.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    263\u001b[0m edge_attr_hc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhc_edge_encoder(edge_attrs))\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# Run the track condenser\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m h_hc, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhc_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_hc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr_hc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m beta \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp_beta(h_hc))\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# Soft clipping to protect against nans when calling arctanh(beta)\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/gnn_tracking/src/gnn_tracking/models/resin.py:296\u001b[0m, in \u001b[0;36mResIN.forward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28mself\u001b[39m, x: T, edge_index: T, edge_attr: T\n\u001b[1;32m    295\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[T, T, \u001b[38;5;28mlist\u001b[39m[T], \u001b[38;5;28mlist\u001b[39m[T] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[0;32m--> 296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gnn_tracking/src/gnn_tracking/models/resin.py:84\u001b[0m, in \u001b[0;36mResidualNetwork.forward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, edge_attr) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[T, T, \u001b[38;5;28mlist\u001b[39m[T] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[1;32m     73\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m        levels (including ``edge_attr``, unless collect_hidden_edges is False)\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gnn_tracking/src/gnn_tracking/models/resin.py:106\u001b[0m, in \u001b[0;36mSkip1ResidualNetwork._forward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_layer, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[1;32m    105\u001b[0m     activation \u001b[38;5;241m=\u001b[39m relu \u001b[38;5;28;01mif\u001b[39;00m i_layer \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m nn\u001b[38;5;241m.\u001b[39mIdentity()\n\u001b[0;32m--> 106\u001b[0m     delta_x, edge_attr \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     x \u001b[38;5;241m=\u001b[39m sqconvex_combination(\n\u001b[1;32m    108\u001b[0m         delta\u001b[38;5;241m=\u001b[39mdelta_x,\n\u001b[1;32m    109\u001b[0m         residue\u001b[38;5;241m=\u001b[39mx,\n\u001b[1;32m    110\u001b[0m         alpha_residue\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_alpha,\n\u001b[1;32m    111\u001b[0m     )\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collect_hidden_edge_embeds:\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/gnn_tracking/src/gnn_tracking/models/interaction_network.py:67\u001b[0m, in \u001b[0;36mInteractionNetwork.forward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     65\u001b[0m assert_feat_dim(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39mnode_indim)\n\u001b[1;32m     66\u001b[0m assert_feat_dim(edge_attr, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39medge_indim)\n\u001b[0;32m---> 67\u001b[0m x_tilde \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_e_tilde \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# mypy\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Make sure that memory is released after the forward pass\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:463\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m         msg_kwargs \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m res\n\u001b[0;32m--> 463\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmsg_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    465\u001b[0m     res \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, (msg_kwargs, ), out)\n",
      "File \u001b[0;32m~/gnn_tracking/src/gnn_tracking/models/interaction_network.py:87\u001b[0m, in \u001b[0;36mInteractionNetwork.message\u001b[0;34m(self, x_i, x_j, edge_attr)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calculate message of an edge\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    Message\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     86\u001b[0m m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x_i, x_j, edge_attr], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_e_tilde \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelational_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_e_tilde \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# mypy\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_e_tilde\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"/home/aj2239/gnn_tracking/src/gnn_tracking/models/mlp.py\", line 49, in forward\n    def forward(self, x):\n        for layer in self.layers:\n            x = layer(x)\n                ~~~~~ <--- HERE\n        return x\n  File \"/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/torch/nn/modules/activation.py\", line 101, in forward\n    def forward(self, input: Tensor) -> Tensor:\n        return F.relu(input, inplace=self.inplace)\n               ~~~~~~ <--- HERE\n  File \"/scratch/gpfs/aj2239/micromamba/envs/gnn/lib/python3.11/site-packages/torch/nn/functional.py\", line 1471, in relu\n        result = torch.relu_(input)\n    else:\n        result = torch.relu(input)\n                 ~~~~~~~~~~ <--- HERE\n    return result\nRuntimeError: CUDA out of memory. Tried to allocate 486.00 MiB. GPU 0 has a total capacty of 9.50 GiB of which 484.94 MiB is free. Process 3006315 has 106.00 MiB memory in use. Including non-PyTorch memory, this process has 8.91 GiB memory in use. Of the allocated memory 7.79 GiB is allocated by PyTorch, and 1.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=1000,\n",
    "    accelerator=\"gpu\",\n",
    "    log_every_n_steps=1,\n",
    "    callbacks=[PrintValidationMetrics()],\n",
    ")\n",
    "trainer.fit(model=lmodel, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
